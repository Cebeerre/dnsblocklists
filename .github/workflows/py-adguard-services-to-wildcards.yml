name: Build AdGuard services -> wildcard lists (Python) + icons + SERVICES.md + README rows

on:
  schedule:
    - cron: "20 3 * * 1"   # weekly: Mon 03:20 UTC
  workflow_dispatch: {}

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      ORIG_SOURCE: https://github.com/AdguardTeam/HostlistsRegistry/tree/main
      TREE_API: https://api.github.com/repos/AdguardTeam/HostlistsRegistry/git/trees/main?recursive=1

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests PyYAML idna

      - name: Build lists, extract icons, write SERVICES.md and update README rows
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python - <<'PY'
          import os, re, sys, time, pathlib
          import requests, yaml, idna
          from requests.adapters import HTTPAdapter, Retry

          REPO = os.environ.get("GITHUB_REPOSITORY", "")
          OWNER, _, NAME = REPO.partition("/")
          PAGES_BASE = f"https://{OWNER}.github.io/{NAME}"
          TREE_API   = os.environ["TREE_API"]
          ORIG_SOURCE= os.environ["ORIG_SOURCE"]
          TOKEN      = os.environ.get("GITHUB_TOKEN", "")

          out_dir  = pathlib.Path("webservices")
          icon_dir = pathlib.Path("icons")
          out_dir.mkdir(parents=True, exist_ok=True)
          icon_dir.mkdir(parents=True, exist_ok=True)

          TS = time.strftime("%Y%m%d%H%M", time.gmtime())

          # HTTP session
          sess = requests.Session()
          retries = Retry(total=2, connect=2, read=2, backoff_factor=1,
                          status_forcelist=(429,500,502,503,504),
                          allowed_methods=frozenset(["GET","HEAD"]))
          sess.mount("http://", HTTPAdapter(max_retries=retries))
          sess.mount("https://", HTTPAdapter(max_retries=retries))
          sess.headers.update({"User-Agent": "adguard-webservices-builder/1.9"})
          if TOKEN:
              sess.headers.update({"Authorization": f"Bearer {TOKEN}"})

          def api_get_json(url: str):
              r = sess.get(url, timeout=(5,20)); r.raise_for_status(); return r.json()
          def cdn_get_bytes(url: str) -> bytes:
              r = requests.get(url, timeout=(5,20)); r.raise_for_status(); return r.content

          # Domain parsing helpers (simplified + IDNA)
          def normalize_domain_ascii(d: str) -> str|None:
              d = d.strip().strip(".").lower()
              if not d or "://" in d or "/" in d or "_" in d or " " in d or "." not in d: return None
              try: return idna.encode(d, uts46=True, std3_rules=True).decode("ascii")
              except idna.IDNAError: return None
          def parse_rule_to_domain(s: str):
              s=s.strip()
              if not s or s.startswith("#") or s.startswith("@@"): return (None,"comment")
              if s.startswith("||"):
                  m=re.match(r"^\|\|([^,^|$]+)", s)
                  if not m: return (None,"malformed_double_pipe")
                  dom=m.group(1).strip().strip(".").lower()
                  if "*" in dom: return (None,"wildcard_inside_label")
                  a=normalize_domain_ascii(dom); return (a, None if a else "invalid")
              if s.startswith("|"): return (None,"single_pipe")
              if s.startswith("*."):
                  rest=s[2:].strip().strip(".").lower()
                  if "*" in rest: return (None,"wildcard_inside_label")
                  a=normalize_domain_ascii(rest); return (a, None if a else "invalid")
              plain=re.split(r"[,|$]", s, 1)[0].strip().strip(".").lower()
              if "*" in plain: return (None,"wildcard_inside_label")
              a=normalize_domain_ascii(plain); return (a, None if a else "invalid")

          # Discover YAML files
          tree = api_get_json(TREE_API)
          files = [t["path"] for t in tree.get("tree", []) if t.get("type")=="blob"]
          svc_paths = [p for p in files if p.startswith("services/") and (p.endswith(".yml") or p.endswith(".yaml"))]

          upstream_sids=set(); icons_written=0

          for rel in sorted(svc_paths):
              raw_url=f"https://raw.githubusercontent.com/AdguardTeam/HostlistsRegistry/main/{rel}"
              yml=yaml.safe_load(cdn_get_bytes(raw_url)) or {}

              sid_raw=(yml.get("id") or yml.get("name") or "unknown")
              sname  =(yml.get("name") or yml.get("id") or "unknown")
              sid=re.sub(r"[^a-z0-9]+","_", str(sid_raw).lower()).strip("_") or "unknown"
              upstream_sids.add(sid)

              icon_svg=yml.get("icon_svg")
              if isinstance(icon_svg,str) and "<svg" in icon_svg.lower():
                  (icon_dir/f"{sid}.svg").write_text(icon_svg.strip(), encoding="utf-8")
                  icons_written+=1

              rules=yml.get("rules") or []
              domains=set(); skipped=[]
              for line in rules:
                  if not isinstance(line,str): continue
                  a,reason=parse_rule_to_domain(line)
                  if a: domains.add(a)
                  elif reason not in ("comment",): skipped.append(line)

              entries_count = len(domains)
              out_path=out_dir/f"{sid}_asterisk.txt"
              with out_path.open("w", encoding="utf-8") as f:
                  f.write(f"# Title: Blocklist for {sname}\n")
                  f.write(f"# Description: Blocks {sname} content (sourced from AdGuardTeam's HostlistsRegistry)\n")
                  f.write(f"# Homepage: https://github.com/{OWNER}/{NAME}\n")
                  f.write(f"# License: https://github.com/{OWNER}/{NAME}/blob/main/LICENSE\n")
                  f.write(f"# Version: {TS}\n")
                  f.write(f"# Original Source: {ORIG_SOURCE}\n")
                  f.write(f"# Syntax: Domains Wildcard - Blocky (v0.23 or newer)\n")
                  f.write(f"# Entries: {entries_count}\n#\n")
                  if skipped:
                      f.write("# Skipped unsupported rules:\n")
                      for s in skipped: f.write(f"# Skipped unsupported rule: {s}\n")
                      f.write("#\n")
                  for d in sorted(domains):
                      f.write(f"*.{d}\n")

          # Build rows (for both SERVICES.md and README injection)
          rows=[]
          for p in sorted(out_dir.glob("*_asterisk.txt")):
              sid=p.name.removesuffix("_asterisk.txt")
              # Use the id for pretty name fallback
              name_pretty=re.sub(r"_+"," ", sid).title()
              pages_url=f"{PAGES_BASE}/webservices/{p.name}"
              icon_rel=f"icons/{sid}.svg"
              icon_md = f'<img src="{icon_rel}" width="20" height="20"/>' if pathlib.Path(icon_rel).exists() else "â€”"
              link_md=f"[{p.name}]({pages_url})"
              rows.append((icon_md, name_pretty, link_md))

          # Write SERVICES.md (full doc)
          md = []
          md.append("## ðŸ“‹ Webservices Blocklists\n")
          md.append("Automatically generated from AdGuard's HostlistsRegistry. Each list is already in wildcard format for Blocky.\n\n")
          md.append("| Icon | Name | Link |\n|------|------|------|\n")
          for icon,name,link in rows:
              md.append(f"| {icon} | {name} | {link} |\n")
          pathlib.Path("SERVICES.md").write_text("".join(md), encoding="utf-8")

          # Inject ONLY ROWS into README between markers
          readme_path=pathlib.Path("README.md")
          if readme_path.exists():
              readme_text=readme_path.read_text(encoding="utf-8")
          else:
              print("README.md not found; skipping injection."); sys.exit(0)

          start="<!-- START:SERVICES -->"
          end="<!-- END:SERVICES -->"
          rows_md = "".join(f"| {icon} | {name} | {link} |\n" for icon,name,link in rows)

          if start in readme_text and end in readme_text:
              new_text = re.sub(
                  rf"{re.escape(start)}.*?{re.escape(end)}",
                  f"{start}\n{rows_md}{end}",
                  readme_text,
                  flags=re.DOTALL
              )
              if new_text != readme_text:
                  readme_path.write_text(new_text, encoding="utf-8")
                  print(f"README rows injected: {len(rows)}")
              else:
                  print("README already up-to-date.")
          else:
              print("Markers not found in README.md; no injection performed.")
          PY

      - name: Commit & push if changed
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore(services): refresh lists, icons, SERVICES.md, inject README rows (20x20 icons)"
          add_options: "-A"
